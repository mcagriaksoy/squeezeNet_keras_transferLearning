{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezeNet_keras_tl_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIXG8QcN2SMQ2NFeFASNtJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcagriaksoy/squeezeNet_keras_transferLearning/blob/main/squeezeNet_keras_tl_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![photo - Kopya.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "2022 - Created By Mehmet Çağrı Aksoy\n",
        "\n",
        "https://orcid.org/0000-0002-7886-7945\n",
        "\n",
        "https://www.researchgate.net/profile/Mehmet-Aksoy-12\n",
        "\n",
        "https://github.com/mcagriaksoy\n",
        "\n",
        "https://www.linkedin.com/in/mcagriaksoy/\n",
        "\n",
        "https://scholar.google.com/citations?user=CKRkg1EAAAAJ&hl=en&oi=ao"
      ],
      "metadata": {
        "id": "y1juLGPerIev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "hQxrGFBgxor-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "0a9IUTiOxpgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Original SqueezeNet solution**\n",
        "\n",
        "Optimized for keras new version and google colaboratory environment\n",
        "\n",
        "The original file (not uptodate) is in rcmalli's repo which is: https://github.com/rcmalli/keras-squeezenet\n",
        "\n",
        "Changes of rcmalli's version:\n",
        "\n",
        "*   warnings call removed.\n",
        "*   get_source_inputs lib call is changed.\n",
        "*   include_top==True check is added which is already in pull_request in repo.\n",
        "\n"
      ],
      "metadata": {
        "id": "-HzF7idcrdyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEs6R-enq-7B"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.utils.layer_utils import get_source_inputs #https://stackoverflow.com/questions/68862735/keras-vggface-no-module-named-keras-engine-topology\n",
        "from tensorflow.keras.utils import get_file\n",
        "from keras.utils import layer_utils\n",
        "\n",
        "\n",
        "sq1x1 = \"squeeze1x1\"\n",
        "exp1x1 = \"expand1x1\"\n",
        "exp3x3 = \"expand3x3\"\n",
        "relu = \"relu_\"\n",
        "\n",
        "WEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "# Modular function for Fire Node\n",
        "\n",
        "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "    s_id = 'fire' + str(fire_id) + '/'\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "    \n",
        "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
        "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
        "    return x\n",
        "\n",
        "\n",
        "# Original SqueezeNet from paper.\n",
        "def SqueezeNet(include_top=True, weights='imagenet',\n",
        "               input_tensor=None, input_shape=None,\n",
        "               pooling=None,\n",
        "               classes=1000):\n",
        "    \"\"\"Instantiates the SqueezeNet architecture.\"\"\"\n",
        "        \n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    if weights == 'imagenet' and classes != 1000 and include_top==True:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    input_shape = input_shape\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "\n",
        "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
        "    x = Activation('relu', name='relu_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "    \n",
        "    if include_top:\n",
        "        x = Dropout(0.5, name='drop9')(x)\n",
        "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "        x = Activation('relu', name='relu_conv10')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Activation('softmax', name='loss')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling=='max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "        elif pooling==None:\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs, x, name='squeezenet')\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                    WEIGHTS_PATH,\n",
        "                                    cache_subdir='models')\n",
        "        else:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                    WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir='models')\n",
        "            \n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning example:**"
      ],
      "metadata": {
        "id": "wYfSToVdsJ0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten"
      ],
      "metadata": {
        "id": "dt7VaYEO0kp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NUMBER_OF_CLASSES = 10 # number of unique digits\n",
        "input_shape = (32,32,3) # cifar10 img size\n",
        "\n",
        "epochs = 30\n",
        "batch_size = 64\n",
        "optimizer = \"Adam\""
      ],
      "metadata": {
        "id": "6UprhfOesU47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = SqueezeNet(weights=\"imagenet\", input_shape=input_shape, include_top=False, pooling = 'avg', classes=NUMBER_OF_CLASSES)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(input_shape))\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "predictions = Dense(NUMBER_OF_CLASSES, activation= 'softmax')(x)\n",
        "\n",
        "SqueezeNet_model = Model(inputs = inputs, outputs = predictions)\n",
        "\n",
        "SqueezeNet_model.summary()\n",
        "\n",
        "SqueezeNet_model.compile(\n",
        "  optimizer= optimizer,\n",
        "  loss= 'sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "# Do not forget to change it with your train-test-val files!\n",
        "history_SqueezeNet_model = SqueezeNet_model.fit(x_train, \n",
        "                                                y_train,\n",
        "                                                validation_data=(x_test,y_test),\n",
        "                                                epochs=epochs,\n",
        "                                                batch_size = batch_size\n",
        "                                                )"
      ],
      "metadata": {
        "id": "nfwbVv1hsPNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Graph Comparison"
      ],
      "metadata": {
        "id": "Nc1xAq-nZq1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80EYzLSQZq1b"
      },
      "outputs": [],
      "source": [
        "plt.plot(history_SqueezeNet_model.history['accuracy'])\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['SqueezeNet ImageNet weights'], loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **No weights Example**"
      ],
      "metadata": {
        "id": "9xBZiHvusn3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SqueezeNet_model = SqueezeNet(weights=None, input_shape=input_shape, pooling = 'avg', classes=NUMBER_OF_CLASSES)\n",
        "\n",
        "SqueezeNet_model.summary()\n",
        "\n",
        "SqueezeNet_model.compile(\n",
        "  optimizer= optimizer,\n",
        "  loss= 'sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "# Do not forget to change it with your train-test-val files!\n",
        "history_SqueezeNet_model = SqueezeNet_model.fit(x_train,\n",
        "                                                y_train,\n",
        "                                                validation_data=(x_test,y_test),\n",
        "                                                epochs=epochs,\n",
        "                                                batch_size = batch_size\n",
        "                                                )"
      ],
      "metadata": {
        "id": "SkZKNMn6svhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}